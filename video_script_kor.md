안녕하세요, 이번 insightfactory.ai Cadet challenge에 지원한 Chanwoo Bae입니다. Preferred name은 Ted입니다.
이번 챌린지에서 구현한 AI 기반 database LLM agent에 대해 데이터베이스 설정부터 쿼리 실행까지 전체 과정을 보여드리겠습니다.

저의 프로덕트는 크게 두 가지로 나뉩니다: 데이터베이스 사전 세팅과 agent chat UI 실행입니다. 

먼저 데이터베이스 사전 세팅은 LLM 모델 기반보다는 유저 인터랙티브 기반으로 설계하였습니다. 데이터베이스 설정 과정을 보여드리며 의도한 설계 방향도 함께 설명드리겠습니다. 

./start.sh를 실행하면 스키마 파일 유무에 따라 바로 UI를 실행하거나 데이터베이스 셋업부터 시작하게 됩니다.

일단 저는 from scratch부터 보여드려야 하므로 데이터베이스 세팅부터 시작합니다. 

세팅이 시작되면 화면에서 안내되는 것과 같이 여섯 단계로 진행됩니다. 

  1. Profiler - Analyze CSV files
  2. Relationship Discovery - Configure PK/FK (interactive)
  3. Load Data - Load to PostgreSQL (may fail initially)
  4. Integrity Checker - Validate data integrity
  5. Transform Data - Fix issues (interactive)
  6. Generate Schema - Create schema with PII detection

1번부터 시작합니다. 첫 스텝은 데이터들의 전체적인 프로파일링을 하는 것입니다. 

[data_profile.json을 보여준다]

데이터별 기본 정보 및 다음 단계들에서 활용될 컬럼별 특징들을 스캔합니다. 이 단계에서는 저장되어 있는 CSV 데이터 파일을 토대로 data_profile.json이 자동으로 생성됩니다. 

이번 Relationship Discovery 단계부터는 사용자와의 인터랙티브로 세팅을 하도록 해놨습니다.

사실 처음에는 LLM으로 자동으로 키를 설정하도록 방향을 잡고 진행했습니다.

그러나 data-agnostic를 준수하고자 하기엔 위험부담이 따랐습니다. 컬럼 네이밍부터 각종 변수들이 너무나 많기 때문입니다. 특히 저장된 CSV 데이터가 백 퍼센트 무결성을 보장하지 않으며, LLM이 직접 판단하거나 혹은 자체적인 키 탐지 로직을 짜면, 한 개만 연결이 제대로 안 되어도 결국 DB 전체가 구축되지 않는 결과에 다다를 수 있기 때문입니다.  

따라서 사용자가 데이터 관리자라는 것을 염두에 두어, CLI 인터페이스 안내에 따라 키를 설정하도록 설계하였습니다.

[프라이머리키 세팅을 시작한다]

먼저 테이블별로 프라이머리 키를 설정합니다.
비록 인터랙티브 방식이지만, 유저 편의를 위해 가장 가능성 있는 컬럼을 추천해주는 시스템도 함께 구현해놨습니다. 사용자는 화면에 보이는 데이터 샘플을 통해 어떤 것이 프라이머리 키인지 직접 판단하고 입력할 수 있도록 구현했습니다. 

[외부키 세팅을 시작한다]

마찬가지로 각 테이블별로 포린키 및 외부 참조를 설정합니다. 먼저 설정할 포린키를 지정한 후 어느 테이블을 참조할지 선택하는 순서입니다. 추천 시스템을 통해 가능성 높은 후보를 제안받을 수 있습니다.

이를 통해 LLM 에이전트 혹은 자동화 로직 의존보다 데이터 무결성 리스크를 최소화하였습니다.

키 세팅을 완료하면 자동으로 데이터를 PostgreSQL 데이터베이스에 입력합니다. 

[로드 데이터 후 CLI 결과창을 보여준다]

그런데 창을 보시면, CSV 데이터 무결성 미확보로 인해 사용자가 앞서 세팅한 키 정보로 입력이 완벽하게 되지 않고 이슈를 발생시킵니다. 그리고 이때 자동으로 인테그리티 체크를 통해 어떤 문제가 있는지 리포트를 해줍니다. 

이때 사용자의 인터랙티브 개입이 한 번 더 이뤄집니다. 이 부분도 마찬가지로 많은 고민을 했으나, 역시 데이터 무결성을 위해서는 사용자의 직접 개입을 통해 완성하는 것이 맞다고 판단되어
CLI 창에 직접 SQL 명령어를 입력하여 데이터베이스 무결성을 마무리 짓도록 하였습니다. 예를 들어 외부키 제약 위반 레코드를 DELETE하거나 참조 무결성을 맞추기 위해 값을 UPDATE하는 등의 작업을 직접 수행합니다.

[SQL 입력을 다 보여준다]

이후 무결성을 자동으로 체크한 후 그다음 PII 체크로 넘어갑니다.

[빨간색 마킹된 곳을 보여준다]

여기서는 LLM이 개입하여 개인정보가 담겨 있을 컬럼을 미리 감지하여 빨간색 마킹을 보여줍니다. 이 리포트를 사용자가 직접 확인하여 해당 개인정보가 마킹됨을 확인합니다.

단 여기서도 혹시나 잘못된 감지가 있을 경우, 스키마 JSON 파일에서 사용자가 직접 수정하도록 안내합니다. 우선 이렇게 하는 것이 제일 간단하지 않을까 판단되어 이러한 방향으로 구현하였습니다.

[src/config/schema_info.json 파일을 보여준다]

이제 스키마 생성이 완료되면 자동으로 서버가 시작되고 UI도 실행됩니다.

참고로 이 프로젝트는 Cerebras의 llama-3.3-70b 모델을 사용하고 있으며, 작업 특성에 따라 최적화된 temperature 설정을 적용했습니다. 예를 들어 intent 분류는 0.0으로 결정론적으로, SQL 생성은 0.1로 정확하게, 그리고 자연어 답변 생성은 0.7로 자연스럽게 생성되도록 설정했습니다.

자, 이제 간단한 질문부터 시작하겠습니다.

[세 개의 질문을 진행한다]

에이전트는 각 질문마다 쿼리 결과를 자연어로 생성해 유저에게 보여줍니다. 이때 매 질문마다 에이전트는 쿼리 결과에 대한 interesting insight를 별도로 생성하도록 구현해놨습니다.

그리고 조금 더 복잡한 질문도 진행해보겠습니다.

[세 개의 질문을 진행한다]

데이터 셋업에서 지정한 마스킹으로 개인 이름은 넘버링 형식으로 가려져서 나옵니다.

자, 이제 다음은 Plotly 차트도 요청해보겠습니다. 현재 bar, line, pie, scatter, area 총 5가지 차트 타입을 지원하며, 에이전트가 질문 내용을 분석하여 가장 적합한 차트 타입을 자동으로 선택합니다. 지금까지는 비주얼라이제이션 요청이 없다고 판단되어 자연어 답변만 생성하였습니다.

[세 개의 질문을 진행한다]

보시는 바와 같이 이번에는 차트 요청에 따라 차트도 함께 답변으로 생성되어 나옵니다. 이어서 PARTITION 등을 활용한 더 복잡한 질문도 요청하겠습니다.

[세 개의 질문을 진행한다]

마찬가지로 답변을 원활하게 생성할 수 있음을 볼 수 있습니다. 자, 이제는 한층 더 심화된 질문을 통해 pyodide로 코드를 생성한 데이터 분석 결과를 보여주도록 하겠습니다. 이것도 마찬가지로 에이전트가 유저의 질문을 판단하여 pyodide를 생성하도록 구현했습니다. 

[시계열 질문을 진행한다]

이번엔 간단한 시계열 질문을 의도했고 pyodide를 생성했습니다. pyodide 코드에서 별도로 결과가 생성되기 때문에 자연어 답변은 간단한 메타데이터 요약만 언급합니다.
추가로 설명드리고 싶은 것은 pyodide가 두 가지 역할을 한다는 것입니다. 첫째로 시계열 분석이나 통계 분석 같은 SQL로 처리하기 어려운 복잡한 데이터 분석을 위한 파이썬 코드 실행 환경이며, 둘째로는 SQL 쿼리가 3회 연속 실패할 경우 자동으로 pyodide 방식으로 전환되어 답변 생성 안정성을 높이는 fallback 메커니즘으로도 활용됩니다. 이를 통해 복잡한 질문에 대한 답변 생성률을 크게 향상시킬 수 있었습니다.

자, 이제 이 프로젝트의 기술 스택 선택 이유와 한계점, 그리고 개선 방향에 대해 간단히 말씀드리겠습니다.

먼저 주요 기술 선택 이유입니다.

Cerebras의 llama-3.3-70b 모델을 선택한 이유는 빠른 추론 속도와 합리적인 가격 때문입니다. OpenAI나 Anthropic에 비해 토큰당 비용이 저렴하면서도 SQL 생성과 자연어 응답에 충분한 성능을 보여줬습니다.

PostgreSQL을 선택한 이유는 관계형 데이터 무결성 보장이 중요했기 때문입니다. MySQL보다 복잡한 쿼리와 JSON 지원이 우수하고, SQLite보다 동시성 처리가 뛰어나 프로덕션 환경에 적합합니다.

Plotly를 선택한 이유는 인터랙티브 차트와 다양한 차트 타입을 기본 제공하기 때문입니다. Chart.js보다 더 많은 차트 옵션을 제공하고, D3.js보다 구현이 간단하면서도 충분히 전문적인 시각화가 가능합니다.

마지막으로 Pyodide를 선택한 이유는 브라우저에서 직접 파이썬을 실행할 수 있기 때문입니다. 서버 사이드에서 실행하는 것보다 보안이 우수하고, 사용자가 생성된 코드를 직접 확인하고 신뢰할 수 있습니다.

다음으로 현재 시스템의 한계점입니다.

가장 큰 한계점은 각 질문을 독립적으로 처리한다는 점입니다. 예를 들어 "상위 5개 제품을 보여줘"라고 질문한 후 "하위 5개는?"이라고 follow-up 질문을 하면, 이전 맥락을 이해하지 못합니다. 현재 아키텍처는 매 질문마다 마지막 메시지만 읽어서 처리하기 때문에 대화 컨텍스트가 유지되지 않습니다.

마지막으로 개선 방향입니다.

향후에는 대화 히스토리를 스키마와 함께 프롬프트에 포함하여 컨텍스트를 활용하는 multi-turn conversation 기능을 추가할 계획입니다. 이를 통해 "그 결과를 차트로 보여줘"나 "같은 조건으로 다른 컬럼도 보여줘"와 같은 자연스러운 follow-up 질문이 가능해질 것입니다.

네, 일단 기본적인 데모 영상은 여기까지로 마치겠습니다. 데모 영상은 시연 위주로 보여드렸으며, 상세 아키텍처 및 워크플로우 등은 docs 폴더에 정리해놨습니다. 지금까지 봐주셔서 감사합니다. 이상입니다.